{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "from datetime import date, datetime\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"/opt/ml/before/input/data/train_data.csv\")\n",
    "df = df.sort_values(by=[\"userID\", \"Timestamp\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv(\"/opt/ml/before/input/data/train_data.csv\")\n",
    "test = pd.read_csv('/opt/ml/before/input/data/test_data.csv')\n",
    "\n",
    "test['answerCode'] = np.full((test.shape[0]), 0)\n",
    "\n",
    "train['train_test'] = train['answerCode']\n",
    "test['train_test'] = np.full((test.shape[0]), -1)\n",
    "\n",
    "df = pd.concat([train, test])\n",
    "df = df.sort_values(by=[\"userID\", \"Timestamp\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"user_correct_answer\"] = (\n",
    "    df.groupby(\"userID\")[\"answerCode\"]\n",
    "    .transform(lambda x: x.cumsum().shift(1))\n",
    "    .fillna(0)\n",
    ")\n",
    "df[\"user_total_answer\"] = df.groupby(\"userID\")[\"answerCode\"].cumcount() + 1\n",
    "df[\"user_acc\"] = (df[\"user_correct_answer\"] / df[\"user_total_answer\"])\n",
    "df['answerCode'] = df['train_test']\n",
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fe(df):\n",
    "    \n",
    "    # assessmentItemID split\n",
    "    df['assessmentItemID0'] = df['assessmentItemID'].str[2]\n",
    "    df['assessmentItemID1'] = df['assessmentItemID'].str[4:7]\n",
    "    df['assessmentItemID2'] = df[\"assessmentItemID\"].apply(lambda x: int(x[-2:]))\n",
    "    \n",
    "    # testID split\n",
    "    df['testId0'] = df['assessmentItemID0']\n",
    "    df['testId1'] = df['assessmentItemID1']\n",
    "    \n",
    "    # assessmentItemid join\n",
    "    df['as0_as1'] =  np.array([str(i)+'_'+str(j) for i, j in zip(list(df.assessmentItemID0), list(df.assessmentItemID1))])\n",
    "    df['as0_as2'] =  np.array([str(i)+'_'+str(j) for i, j in zip(list(df.assessmentItemID0), list(df.assessmentItemID2))])\n",
    "    df['as1_as2'] =  np.array([str(i)+'_'+str(j) for i, j in zip(list(df.assessmentItemID1), list(df.assessmentItemID2))])\n",
    "    \n",
    "    # time split\n",
    "    df['month'] = df.Timestamp.str[5:7]\n",
    "    df['hour'] = df.Timestamp.str[11:13]\n",
    "\n",
    "    yy = df.Timestamp.str[:4]\n",
    "    mm = df.Timestamp.str[5:7]\n",
    "    dd = df.Timestamp.str[8:10]\n",
    "\n",
    "    y = [int(y) for y in list(yy)]\n",
    "    m = [int(m) for m in list(mm)]\n",
    "    d = [int(d) for d in list(dd)]\n",
    "\n",
    "    df['week'] = [date(i,j,k).weekday() for i,j,k in zip(y,m,d)]\n",
    "    w_h = [str(i)+'_'+j for i, j in zip(list(df.week), list(df.hour))]\n",
    "    df['week_hour'] = w_h\n",
    "    df['day'] = dd\n",
    "    df['minute'] = df.Timestamp.str[14:16]\n",
    "    df['second'] = df.Timestamp.str[17:19]\n",
    "\n",
    "\n",
    "    # elapsed time\n",
    "    def convert_time(s):\n",
    "        timestamp = time.mktime(\n",
    "            datetime.strptime(s, \"%Y-%m-%d %H:%M:%S\").timetuple()\n",
    "        )\n",
    "        return int(timestamp)\n",
    "\n",
    "    df['Time'] = df.Timestamp.apply(convert_time)\n",
    "    \n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    diff = df.loc[:, ['userID', 'Timestamp']].groupby('userID').diff().fillna(pd.Timedelta(seconds=0))\n",
    "    diff = diff.fillna(pd.Timedelta(seconds=0))\n",
    "    diff = diff['Timestamp'].apply(lambda x: x.total_seconds())\n",
    "\n",
    "    df['elapsed'] = diff\n",
    "    df[\"elapsed_log\"] = df[\"elapsed\"].apply(lambda x: math.log(x + 1))\n",
    "    \n",
    "    df[\"elapsed\"] = df[\"elapsed\"].apply(\n",
    "        lambda x: x if x < 1800 and x >= 0 else 0)\n",
    "\n",
    "    def elap(x):\n",
    "        if x == 0:\n",
    "            return 0\n",
    "        elif x < 9:\n",
    "            return 1\n",
    "        elif x < 301:\n",
    "            return 2\n",
    "        elif x < 601:\n",
    "            return 3\n",
    "        elif x < 1201:\n",
    "            return 4\n",
    "        elif x < 1501:\n",
    "            return 5\n",
    "        elif x < 1801:\n",
    "            return 6\n",
    "        else:\n",
    "            return 7\n",
    "\n",
    "    df['elapsed_cate'] = df.elapsed.apply(lambda x : elap(x))\n",
    "    \n",
    "    correct_k = df.groupby([\"KnowledgeTag\"])[\"answerCode\"].agg([\"mean\", \"std\"])\n",
    "    correct_k.columns = [\"tag_mean\", \"tag_std\"]\n",
    "\n",
    "    correct_a = df.groupby([\"assessmentItemID0\"])[\"answerCode\"].agg([\"mean\", \"std\"])\n",
    "    correct_a.columns = [\"ass0_mean\", \"ass0_std\"]\n",
    "    correct_a1 = df.groupby([\"assessmentItemID1\"])[\"answerCode\"].agg([\"mean\", \"std\"])\n",
    "    correct_a1.columns = [\"ass1_mean\", \"ass1_std\"]\n",
    "    correct_a2 = df.groupby([\"assessmentItemID2\"])[\"answerCode\"].agg([\"mean\", \"std\"])\n",
    "    correct_a2.columns = [\"ass2_mean\", \"ass2_std\"]\n",
    "\n",
    "    \n",
    "    df = pd.merge(df, correct_k, on=[\"KnowledgeTag\"], how=\"left\")\n",
    "    df = pd.merge(df, correct_a, on=[\"assessmentItemID0\"], how=\"left\")\n",
    "    df = pd.merge(df, correct_a1, on=[\"assessmentItemID1\"], how=\"left\")\n",
    "    df = pd.merge(df, correct_a2, on=[\"assessmentItemID2\"], how=\"left\")\n",
    "    \n",
    "    \n",
    "    df['test0_mean'] = df['ass0_mean']\n",
    "    df['test0_std'] = df['ass0_std']\n",
    "    df['test1_mean'] = df['ass1_mean']\n",
    "    df['test1_std'] = df['ass1_std']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elo probability\n",
    "\n",
    "def ELO_function(df):\n",
    "    def get_new_theta(is_good_answer, beta, left_asymptote, theta, nb_previous_answers):\n",
    "        return theta + learning_rate_theta(nb_previous_answers) * (\n",
    "            is_good_answer - probability_of_good_answer(theta, beta, left_asymptote)\n",
    "        )\n",
    "\n",
    "    def get_new_beta(is_good_answer, beta, left_asymptote, theta, nb_previous_answers):\n",
    "        return beta - learning_rate_beta(nb_previous_answers) * (\n",
    "            is_good_answer - probability_of_good_answer(theta, beta, left_asymptote)\n",
    "        )\n",
    "\n",
    "    def learning_rate_theta(nb_answers):\n",
    "        return max(0.3 / (1 + 0.01 * nb_answers), 0.04)\n",
    "\n",
    "    def learning_rate_beta(nb_answers):\n",
    "        return 1 / (1 + 0.05 * nb_answers)\n",
    "\n",
    "    def probability_of_good_answer(theta, beta, left_asymptote):\n",
    "        return left_asymptote + (1 - left_asymptote) * sigmoid(theta - beta)\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def estimate_parameters(answers_df, granularity_feature_name=\"assessmentItemID\"):\n",
    "        item_parameters = {\n",
    "            granularity_feature_value: {\"beta\": 0, \"nb_answers\": 0}\n",
    "            for granularity_feature_value in np.unique(\n",
    "                answers_df[granularity_feature_name]\n",
    "            )\n",
    "        }\n",
    "        student_parameters = {\n",
    "            student_id: {\"theta\": 0, \"nb_answers\": 0}\n",
    "            for student_id in np.unique(answers_df.userID)\n",
    "        }\n",
    "\n",
    "        print(\"Parameter estimation is starting...\")\n",
    "\n",
    "        for student_id, item_id, left_asymptote, answered_correctly in tqdm(\n",
    "            zip(\n",
    "                answers_df.userID.values,\n",
    "                answers_df[granularity_feature_name].values,\n",
    "                answers_df.left_asymptote.values,\n",
    "                answers_df.answerCode.values,\n",
    "            )\n",
    "        ):\n",
    "            theta = student_parameters[student_id][\"theta\"]\n",
    "            beta = item_parameters[item_id][\"beta\"]\n",
    "\n",
    "            item_parameters[item_id][\"beta\"] = get_new_beta(\n",
    "                answered_correctly,\n",
    "                beta,\n",
    "                left_asymptote,\n",
    "                theta,\n",
    "                item_parameters[item_id][\"nb_answers\"],\n",
    "            )\n",
    "            student_parameters[student_id][\"theta\"] = get_new_theta(\n",
    "                answered_correctly,\n",
    "                beta,\n",
    "                left_asymptote,\n",
    "                theta,\n",
    "                student_parameters[student_id][\"nb_answers\"],\n",
    "            )\n",
    "\n",
    "            item_parameters[item_id][\"nb_answers\"] += 1\n",
    "            student_parameters[student_id][\"nb_answers\"] += 1\n",
    "\n",
    "        print(f\"Theta & beta estimations on {granularity_feature_name} are completed.\")\n",
    "        return student_parameters, item_parameters\n",
    "\n",
    "    def gou_func(theta, beta):\n",
    "        return 1 / (1 + np.exp(-(theta - beta)))\n",
    "\n",
    "    df[\"left_asymptote\"] = 0\n",
    "\n",
    "    print(f\"Dataset of shape {df.shape}\")\n",
    "    print(f\"Columns are {list(df.columns)}\")\n",
    "\n",
    "    student_parameters, item_parameters = estimate_parameters(df)\n",
    "\n",
    "    prob = [\n",
    "        gou_func(student_parameters[student][\"theta\"], item_parameters[item][\"beta\"])\n",
    "        for student, item in zip(df.userID.values, df.assessmentItemID.values)\n",
    "    ]\n",
    "\n",
    "    df[\"elo_prob\"] = prob\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "cate = ['KnowledgeTag', 'month', 'hour', 'week', 'elapsed_cate', 'testId0', 'testId1',\n",
    "        'assessmentItemID0', 'assessmentItemID1', 'assessmentItemID2', 'day', 'minute', 'second',\n",
    "        'as0_as1', 'as0_as2', 'as1_as2', 'assessmentItemID', 'week_hour']\n",
    "\n",
    "conti = ['elapsed' , 'tag_mean', 'tag_std', 'ass0_mean', 'ass0_std', 'elapsed_log',\n",
    "        'ass1_mean', 'ass1_std', 'ass2_mean', 'ass2_std', 'user_correct_answer', 'Time'\n",
    "        'user_total_answer', 'user_acc', 'recAccuracy', 'recCount', 'solve_order']\n",
    "\n",
    "for i in cate:\n",
    "    cate2label = {j:i for i,j in enumerate(df[i].unique())}\n",
    "    df[i] = df[i].map(cate2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train & test splilt\n",
    "\n",
    "train = df[df['answerCode'] != -1]\n",
    "test = df[df['answerCode'] == -1]\n",
    "\n",
    "train.to_csv('../../elo.csv', index=False)\n",
    "test.to_csv('../../infer.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_file = df[df['rr'] == -1]\n",
    "infer_file.drop(['r', 'rr'], axis=1)\n",
    "infer_file.to_csv('../../../data/infer.csv', index=False)\n",
    "df = df[df['rr'] != -1]\n",
    "df = df.drop(['r', 'rr'], axis=1)\n",
    "df.to_csv('../../../data/elo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>assessmentItemID</th>\n",
       "      <th>testId</th>\n",
       "      <th>answerCode</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>KnowledgeTag</th>\n",
       "      <th>assessmentItemID0</th>\n",
       "      <th>assessmentItemID1</th>\n",
       "      <th>assessmentItemID2</th>\n",
       "      <th>testId0</th>\n",
       "      <th>...</th>\n",
       "      <th>ass1_mean</th>\n",
       "      <th>ass1_std</th>\n",
       "      <th>ass2_mean</th>\n",
       "      <th>ass2_std</th>\n",
       "      <th>test0_mean</th>\n",
       "      <th>test0_std</th>\n",
       "      <th>test1_mean</th>\n",
       "      <th>test1_std</th>\n",
       "      <th>left_asymptote</th>\n",
       "      <th>elo_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001001</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:11</td>\n",
       "      <td>7224</td>\n",
       "      <td>6</td>\n",
       "      <td>001</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710348</td>\n",
       "      <td>0.453616</td>\n",
       "      <td>0.749916</td>\n",
       "      <td>0.433062</td>\n",
       "      <td>0.709232</td>\n",
       "      <td>0.454118</td>\n",
       "      <td>0.710348</td>\n",
       "      <td>0.453616</td>\n",
       "      <td>0</td>\n",
       "      <td>0.979350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001002</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:14</td>\n",
       "      <td>7225</td>\n",
       "      <td>6</td>\n",
       "      <td>001</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710348</td>\n",
       "      <td>0.453616</td>\n",
       "      <td>0.720062</td>\n",
       "      <td>0.448969</td>\n",
       "      <td>0.709232</td>\n",
       "      <td>0.454118</td>\n",
       "      <td>0.710348</td>\n",
       "      <td>0.453616</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001003</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:22</td>\n",
       "      <td>7225</td>\n",
       "      <td>6</td>\n",
       "      <td>001</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710348</td>\n",
       "      <td>0.453616</td>\n",
       "      <td>0.687773</td>\n",
       "      <td>0.463402</td>\n",
       "      <td>0.709232</td>\n",
       "      <td>0.454118</td>\n",
       "      <td>0.710348</td>\n",
       "      <td>0.453616</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001004</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:29</td>\n",
       "      <td>7225</td>\n",
       "      <td>6</td>\n",
       "      <td>001</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710348</td>\n",
       "      <td>0.453616</td>\n",
       "      <td>0.663364</td>\n",
       "      <td>0.472560</td>\n",
       "      <td>0.709232</td>\n",
       "      <td>0.454118</td>\n",
       "      <td>0.710348</td>\n",
       "      <td>0.453616</td>\n",
       "      <td>0</td>\n",
       "      <td>0.972448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001005</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:36</td>\n",
       "      <td>7225</td>\n",
       "      <td>6</td>\n",
       "      <td>001</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710348</td>\n",
       "      <td>0.453616</td>\n",
       "      <td>0.599134</td>\n",
       "      <td>0.490075</td>\n",
       "      <td>0.709232</td>\n",
       "      <td>0.454118</td>\n",
       "      <td>0.710348</td>\n",
       "      <td>0.453616</td>\n",
       "      <td>0</td>\n",
       "      <td>0.957230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266581</th>\n",
       "      <td>7441</td>\n",
       "      <td>A030071005</td>\n",
       "      <td>A030000071</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-05 06:50:21</td>\n",
       "      <td>438</td>\n",
       "      <td>3</td>\n",
       "      <td>071</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638852</td>\n",
       "      <td>0.480351</td>\n",
       "      <td>0.599134</td>\n",
       "      <td>0.490075</td>\n",
       "      <td>0.702238</td>\n",
       "      <td>0.457275</td>\n",
       "      <td>0.638852</td>\n",
       "      <td>0.480351</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266582</th>\n",
       "      <td>7441</td>\n",
       "      <td>A040165001</td>\n",
       "      <td>A040000165</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-21 01:06:39</td>\n",
       "      <td>8836</td>\n",
       "      <td>4</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710708</td>\n",
       "      <td>0.453464</td>\n",
       "      <td>0.749916</td>\n",
       "      <td>0.433062</td>\n",
       "      <td>0.684056</td>\n",
       "      <td>0.464891</td>\n",
       "      <td>0.710708</td>\n",
       "      <td>0.453464</td>\n",
       "      <td>0</td>\n",
       "      <td>0.632742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266583</th>\n",
       "      <td>7441</td>\n",
       "      <td>A040165002</td>\n",
       "      <td>A040000165</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-21 01:06:50</td>\n",
       "      <td>8836</td>\n",
       "      <td>4</td>\n",
       "      <td>165</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710708</td>\n",
       "      <td>0.453464</td>\n",
       "      <td>0.720062</td>\n",
       "      <td>0.448969</td>\n",
       "      <td>0.684056</td>\n",
       "      <td>0.464891</td>\n",
       "      <td>0.710708</td>\n",
       "      <td>0.453464</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266584</th>\n",
       "      <td>7441</td>\n",
       "      <td>A040165003</td>\n",
       "      <td>A040000165</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-21 01:07:36</td>\n",
       "      <td>8836</td>\n",
       "      <td>4</td>\n",
       "      <td>165</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710708</td>\n",
       "      <td>0.453464</td>\n",
       "      <td>0.687773</td>\n",
       "      <td>0.463402</td>\n",
       "      <td>0.684056</td>\n",
       "      <td>0.464891</td>\n",
       "      <td>0.710708</td>\n",
       "      <td>0.453464</td>\n",
       "      <td>0</td>\n",
       "      <td>0.738609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266585</th>\n",
       "      <td>7441</td>\n",
       "      <td>A040165004</td>\n",
       "      <td>A040000165</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-21 01:08:49</td>\n",
       "      <td>8836</td>\n",
       "      <td>4</td>\n",
       "      <td>165</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710708</td>\n",
       "      <td>0.453464</td>\n",
       "      <td>0.663364</td>\n",
       "      <td>0.472560</td>\n",
       "      <td>0.684056</td>\n",
       "      <td>0.464891</td>\n",
       "      <td>0.710708</td>\n",
       "      <td>0.453464</td>\n",
       "      <td>0</td>\n",
       "      <td>0.462240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2266586 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userID assessmentItemID      testId  answerCode           Timestamp  \\\n",
       "0             0       A060001001  A060000001           1 2020-03-24 00:17:11   \n",
       "1             0       A060001002  A060000001           1 2020-03-24 00:17:14   \n",
       "2             0       A060001003  A060000001           1 2020-03-24 00:17:22   \n",
       "3             0       A060001004  A060000001           1 2020-03-24 00:17:29   \n",
       "4             0       A060001005  A060000001           1 2020-03-24 00:17:36   \n",
       "...         ...              ...         ...         ...                 ...   \n",
       "2266581    7441       A030071005  A030000071           0 2020-06-05 06:50:21   \n",
       "2266582    7441       A040165001  A040000165           1 2020-08-21 01:06:39   \n",
       "2266583    7441       A040165002  A040000165           1 2020-08-21 01:06:50   \n",
       "2266584    7441       A040165003  A040000165           1 2020-08-21 01:07:36   \n",
       "2266585    7441       A040165004  A040000165           1 2020-08-21 01:08:49   \n",
       "\n",
       "         KnowledgeTag assessmentItemID0 assessmentItemID1  assessmentItemID2  \\\n",
       "0                7224                 6               001                  1   \n",
       "1                7225                 6               001                  2   \n",
       "2                7225                 6               001                  3   \n",
       "3                7225                 6               001                  4   \n",
       "4                7225                 6               001                  5   \n",
       "...               ...               ...               ...                ...   \n",
       "2266581           438                 3               071                  5   \n",
       "2266582          8836                 4               165                  1   \n",
       "2266583          8836                 4               165                  2   \n",
       "2266584          8836                 4               165                  3   \n",
       "2266585          8836                 4               165                  4   \n",
       "\n",
       "        testId0  ... ass1_mean  ass1_std ass2_mean  ass2_std test0_mean  \\\n",
       "0             6  ...  0.710348  0.453616  0.749916  0.433062   0.709232   \n",
       "1             6  ...  0.710348  0.453616  0.720062  0.448969   0.709232   \n",
       "2             6  ...  0.710348  0.453616  0.687773  0.463402   0.709232   \n",
       "3             6  ...  0.710348  0.453616  0.663364  0.472560   0.709232   \n",
       "4             6  ...  0.710348  0.453616  0.599134  0.490075   0.709232   \n",
       "...         ...  ...       ...       ...       ...       ...        ...   \n",
       "2266581       3  ...  0.638852  0.480351  0.599134  0.490075   0.702238   \n",
       "2266582       4  ...  0.710708  0.453464  0.749916  0.433062   0.684056   \n",
       "2266583       4  ...  0.710708  0.453464  0.720062  0.448969   0.684056   \n",
       "2266584       4  ...  0.710708  0.453464  0.687773  0.463402   0.684056   \n",
       "2266585       4  ...  0.710708  0.453464  0.663364  0.472560   0.684056   \n",
       "\n",
       "        test0_std  test1_mean test1_std left_asymptote  elo_prob  \n",
       "0        0.454118    0.710348  0.453616              0  0.979350  \n",
       "1        0.454118    0.710348  0.453616              0  0.970579  \n",
       "2        0.454118    0.710348  0.453616              0  0.942168  \n",
       "3        0.454118    0.710348  0.453616              0  0.972448  \n",
       "4        0.454118    0.710348  0.453616              0  0.957230  \n",
       "...           ...         ...       ...            ...       ...  \n",
       "2266581  0.457275    0.638852  0.480351              0  0.281925  \n",
       "2266582  0.464891    0.710708  0.453464              0  0.632742  \n",
       "2266583  0.464891    0.710708  0.453464              0  0.615929  \n",
       "2266584  0.464891    0.710708  0.453464              0  0.738609  \n",
       "2266585  0.464891    0.710708  0.453464              0  0.462240  \n",
       "\n",
       "[2266586 rows x 39 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv('/opt/ml/input/data/test_elo.csv')\n",
    "\n",
    "elo = []\n",
    "for i in range(len(a)):\n",
    "    if a['answerCode'].iloc[i] == -1:\n",
    "        elo.append(a['elo_prob'].iloc[i-1])\n",
    "    else:\n",
    "        elo.append(a['elo_prob'].iloc[i])\n",
    "        \n",
    "a['elo_prob'] = elo\n",
    "\n",
    "a.to_csv('/opt/ml/input/data/test_elo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_last_problem(df):\n",
    "    new = []\n",
    "    pre = df[\"testId\"][0]\n",
    "    for idx in df[\"testId\"]:\n",
    "        if pre != idx:\n",
    "            new[-1] = -1\n",
    "            pre = idx\n",
    "        new.append(0)\n",
    "    df[\"last_problem\"] = new\n",
    "    return df\n",
    "\n",
    "dtype = {\"userID\": \"int16\", \"answerCode\": \"int8\", \"KnowledgeTag\": \"int16\"}\n",
    "\n",
    "df = pd.read_csv('../../data/test_data.csv', dtype=dtype, parse_dates=[\"Timestamp\"])\n",
    "df = df.sort_values(by=[\"userID\", \"Timestamp\"]).reset_index(drop=True)\n",
    "\n",
    "df[\"problem_number\"] = df[\"assessmentItemID\"].apply(lambda x: int(x[-3:]))\n",
    "\n",
    "correct_t = df.groupby([\"testId\"])[\"answerCode\"].agg([\"mean\", \"sum\"])\n",
    "correct_t.columns = [\"test_mean\", \"test_sum\"]\n",
    "correct_k = df.groupby([\"KnowledgeTag\"])[\"answerCode\"].agg([\"mean\", \"sum\"])\n",
    "correct_k.columns = [\"tag_mean\", \"tag_sum\"]\n",
    "correct_a = df.groupby([\"assessmentItemID\"])[\"answerCode\"].agg([\"mean\", \"sum\"])\n",
    "correct_a.columns = [\"ass_mean\", \"ass_sum\"]\n",
    "correct_p = df.groupby([\"problem_number\"])[\"answerCode\"].agg([\"mean\", \"sum\"])\n",
    "correct_p.columns = [\"prb_mean\", \"prb_sum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    print(\"-\" * 20, \"Feature Engineering Start\", \"-\" * 20)\n",
    "    start_time = time.time()\n",
    "    # 유저별 시퀀스를 고려하기 위해 아래와 같이 정렬\n",
    "    df.sort_values(by=[\"userID\", \"Timestamp\"], inplace=True)\n",
    "    df = add_last_problem(df)\n",
    "    \n",
    "    # elo 추가\n",
    "    # df = ELO_function(df)\n",
    "\n",
    "    df[\"hour\"] = df[\"Timestamp\"].dt.hour\n",
    "    df[\"dow\"] = df[\"Timestamp\"].dt.dayofweek\n",
    "\n",
    "    # 푸는 시간\n",
    "    diff = (\n",
    "        df.loc[:, [\"userID\", \"Timestamp\"]]\n",
    "        .groupby(\"userID\")\n",
    "        .diff()\n",
    "        .fillna(pd.Timedelta(seconds=0))\n",
    "    )\n",
    "    diff = diff.fillna(pd.Timedelta(seconds=0))\n",
    "    diff = diff[\"Timestamp\"].apply(lambda x: x.total_seconds())\n",
    "    df[\"elapsed\"] = diff\n",
    "    df[\"elapsed\"] = df[\"elapsed\"].apply(lambda x: x if x < 600 and x >= 0 else 0)\n",
    "    def elap(x):\n",
    "        if x == 0:\n",
    "            return 0\n",
    "        elif x < 9:\n",
    "            return 1\n",
    "        elif x < 101:\n",
    "            return 2\n",
    "        elif x < 201:\n",
    "            return 3\n",
    "        elif x < 301:\n",
    "            return 4\n",
    "        elif x < 401:\n",
    "            return 5\n",
    "        elif x < 501:\n",
    "            return 6\n",
    "        elif x < 601:\n",
    "            return 7\n",
    "        \n",
    "    df.elapsed = df.elapsed.apply(lambda x : elap(x))\n",
    "\n",
    "    df[\"grade\"] = df[\"testId\"].apply(lambda x: int(x[2]))\n",
    "    df[\"mid\"] = df[\"testId\"].apply(lambda x: x[7:10])\n",
    "    df[\"problem_number\"] = df[\"assessmentItemID\"].apply(lambda x: int(x[-3:]))\n",
    "    df['assessmentItemID0'] = df['assessmentItemID'].str[2]\n",
    "    df['assessmentItemID1'] = df['assessmentItemID'].str[4:7]\n",
    "    \n",
    "    correct_h = df.groupby([\"hour\"])[\"answerCode\"].agg([\"mean\", \"sum\"])\n",
    "    correct_h.columns = [\"hour_mean\", \"hour_sum\"]\n",
    "    correct_d = df.groupby([\"dow\"])[\"answerCode\"].agg([\"mean\", \"sum\"])\n",
    "    correct_d.columns = [\"dow_mean\", \"dow_sum\"]\n",
    "\n",
    "    df = pd.merge(df, correct_t, on=[\"testId\"], how=\"left\")\n",
    "    df = pd.merge(df, correct_k, on=[\"KnowledgeTag\"], how=\"left\")\n",
    "    df = pd.merge(df, correct_a, on=[\"assessmentItemID\"], how=\"left\")\n",
    "    df = pd.merge(df, correct_p, on=[\"problem_number\"], how=\"left\")\n",
    "    df = pd.merge(df, correct_h, on=[\"hour\"], how=\"left\")\n",
    "    df = pd.merge(df, correct_d, on=[\"dow\"], how=\"left\")\n",
    "\n",
    "    o_df = df[df[\"answerCode\"] == 1]\n",
    "    x_df = df[df[\"answerCode\"] == 0]\n",
    "\n",
    "    elp_k = df.groupby([\"KnowledgeTag\"])[\"elapsed\"].agg(\"mean\").reset_index()\n",
    "    elp_k.columns = [\"KnowledgeTag\", \"tag_elp\"]\n",
    "    elp_k_o = o_df.groupby([\"KnowledgeTag\"])[\"elapsed\"].agg(\"mean\").reset_index()\n",
    "    elp_k_o.columns = [\"KnowledgeTag\", \"tag_elp_o\"]\n",
    "    elp_k_x = x_df.groupby([\"KnowledgeTag\"])[\"elapsed\"].agg(\"mean\").reset_index()\n",
    "    elp_k_x.columns = [\"KnowledgeTag\", \"tag_elp_x\"]\n",
    "\n",
    "    df = pd.merge(df, elp_k, on=[\"KnowledgeTag\"], how=\"left\")\n",
    "    df = pd.merge(df, elp_k_o, on=[\"KnowledgeTag\"], how=\"left\")\n",
    "    df = pd.merge(df, elp_k_x, on=[\"KnowledgeTag\"], how=\"left\")\n",
    "\n",
    "    ass_k = df.groupby([\"assessmentItemID0\"])[\"elapsed\"].agg(\"mean\").reset_index()\n",
    "    ass_k.columns = [\"assessmentItemID0\", \"ass_elp\"]\n",
    "    ass_k_o = o_df.groupby([\"assessmentItemID0\"])[\"elapsed\"].agg(\"mean\").reset_index()\n",
    "    ass_k_o.columns = [\"assessmentItemID0\", \"ass_elp_o\"]\n",
    "    ass_k_x = x_df.groupby([\"assessmentItemID0\"])[\"elapsed\"].agg(\"mean\").reset_index()\n",
    "    ass_k_x.columns = [\"assessmentItemID0\", \"ass_elp_x\"]\n",
    "\n",
    "    df = pd.merge(df, ass_k, on=[\"assessmentItemID0\"], how=\"left\")\n",
    "    df = pd.merge(df, ass_k_o, on=[\"assessmentItemID0\"], how=\"left\")\n",
    "    df = pd.merge(df, ass_k_x, on=[\"assessmentItemID0\"], how=\"left\")\n",
    "\n",
    "    prb_k = df.groupby([\"problem_number\"])[\"elapsed\"].agg(\"mean\").reset_index()\n",
    "    prb_k.columns = [\"problem_number\", \"prb_elp\"]\n",
    "    prb_k_o = o_df.groupby([\"problem_number\"])[\"elapsed\"].agg(\"mean\").reset_index()\n",
    "    prb_k_o.columns = [\"problem_number\", \"prb_elp_o\"]\n",
    "    prb_k_x = x_df.groupby([\"problem_number\"])[\"elapsed\"].agg(\"mean\").reset_index()\n",
    "    prb_k_x.columns = [\"problem_number\", \"prb_elp_x\"]\n",
    "\n",
    "    df = pd.merge(df, prb_k, on=[\"problem_number\"], how=\"left\")\n",
    "    df = pd.merge(df, prb_k_o, on=[\"problem_number\"], how=\"left\")\n",
    "    df = pd.merge(df, prb_k_x, on=[\"problem_number\"], how=\"left\")\n",
    "\n",
    "    df[\"user_correct_answer\"] = (\n",
    "        df.groupby(\"userID\")[\"answerCode\"]\n",
    "        .transform(lambda x: x.cumsum().shift(1))\n",
    "        .fillna(0)\n",
    "    )\n",
    "    df[\"user_total_answer\"] = df.groupby(\"userID\")[\"answerCode\"].cumcount()\n",
    "    df[\"user_acc\"] = (df[\"user_correct_answer\"] / df[\"user_total_answer\"]).fillna(0)\n",
    "    df[\"Grade_o\"] = (\n",
    "        df.groupby([\"userID\", \"grade\"])[\"answerCode\"]\n",
    "        .transform(lambda x: x.cumsum().shift(1))\n",
    "        .fillna(0)\n",
    "    )\n",
    "    df[\"GradeCount\"] = df.groupby([\"userID\", \"grade\"]).cumcount()\n",
    "    df[\"GradeAcc\"] = (df[\"Grade_o\"] / df[\"GradeCount\"]).fillna(0)\n",
    "    df[\"GradeElp\"] = (\n",
    "        df.groupby([\"userID\", \"grade\"])[\"elapsed\"]\n",
    "        .transform(lambda x: x.cumsum())\n",
    "        .fillna(0)\n",
    "    )\n",
    "    df[\"GradeMElp\"] = df[\"GradeElp\"] / [\n",
    "        v if v != 0 else 1 for v in df[\"GradeCount\"].values\n",
    "    ]\n",
    "\n",
    "    f = lambda x: len(set(x))\n",
    "    test = df.groupby([\"testId\"]).agg({\"problem_number\": \"max\", \"KnowledgeTag\": f})\n",
    "    test.reset_index(inplace=True)\n",
    "\n",
    "    test.columns = [\"testId\", \"problem_count\", \"tag_count\"]\n",
    "\n",
    "    df = pd.merge(df, test, on=\"testId\", how=\"left\")\n",
    "\n",
    "    gdf = df[[\"userID\", \"testId\", \"problem_number\", \"grade\", \"Timestamp\"]].sort_values(\n",
    "        by=[\"userID\", \"grade\", \"Timestamp\"]\n",
    "    )\n",
    "    gdf[\"buserID\"] = gdf[\"userID\"] != gdf[\"userID\"].shift(1)\n",
    "    gdf[\"bgrade\"] = gdf[\"grade\"] != gdf[\"grade\"].shift(1)\n",
    "    gdf[\"first\"] = gdf[[\"buserID\", \"bgrade\"]].any(axis=1).apply(lambda x: 1 - int(x))\n",
    "    gdf[\"RepeatedTime\"] = gdf[\"Timestamp\"].diff().fillna(pd.Timedelta(seconds=0))\n",
    "    gdf[\"RepeatedTime\"] = (\n",
    "        gdf[\"RepeatedTime\"].apply(lambda x: x.total_seconds()) * gdf[\"first\"]\n",
    "    )\n",
    "    df[\"RepeatedTime\"] = gdf[\"RepeatedTime\"].apply(lambda x: math.log(x + 1))\n",
    "\n",
    "    df[\"prior_KnowledgeTag_frequency\"] = df.groupby(\n",
    "        [\"userID\", \"KnowledgeTag\"]\n",
    "    ).cumcount()\n",
    "\n",
    "    df[\"problem_position\"] = df[\"problem_number\"] / df[\"problem_count\"]\n",
    "    df[\"solve_order\"] = df.groupby([\"userID\", \"testId\"]).cumcount()\n",
    "    df[\"solve_order\"] = (\n",
    "        df[\"solve_order\"]\n",
    "        - df[\"problem_count\"] * (df[\"solve_order\"] > df[\"problem_count\"]).apply(int)\n",
    "        + 1\n",
    "    )\n",
    "    df[\"retest\"] = (df[\"solve_order\"] > df[\"problem_count\"]).apply(int)\n",
    "    T = df[\"solve_order\"] != df[\"problem_number\"]\n",
    "    TT = T.shift(1)\n",
    "    TT[0] = False\n",
    "    df[\"solved_disorder\"] = (TT.apply(lambda x: not x) & T).apply(int)\n",
    "\n",
    "    #df[\"testId\"] = df[\"testId\"].apply(lambda x: int(x[1:4] + x[-3]))\n",
    "\n",
    "    print(\"-\" * 20, \"Feature Engineering End\", \"-\" * 20)\n",
    "    print(f\"Feature Engineering에 걸린 시간 : {time.time() - start_time}s\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('dkt_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fad12edb636dbc78e3b80fe6e41250393276d94079fcdfeefbbba96c125c63ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
