{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86cd7332-c20f-44c7-b764-266d5da61be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def acsu(n):\n",
    "    return sum([2 for i in range(2, int(n**0.5)+1) if n%i ==0]) + 2 - (int(n**0.5) == n**0.5)*1\n",
    "\n",
    "def solution(number, limit, power):\n",
    "    return [min([acsu(i+1), power]) for i in range(number)]\n",
    "\n",
    "solution(5,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c458f05-91ed-48c6-a8f2-32e863a49376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee0ae61-c9dd-41a6-9e4a-01b2826acef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/elo.csv')\n",
    "\n",
    "def custom_train_test_split(df, ratio=0.7, split=True):\n",
    "    \n",
    "    users = list(zip(df['userID'].value_counts().index, df['userID'].value_counts()))\n",
    "    random.shuffle(users)\n",
    "    \n",
    "    max_train_data_len = ratio*len(df)\n",
    "    sum_of_train_data = 0\n",
    "    user_ids =[]\n",
    "\n",
    "    for user_id, count in users:\n",
    "        sum_of_train_data += count\n",
    "        if max_train_data_len < sum_of_train_data:\n",
    "            break\n",
    "        user_ids.append(user_id)\n",
    "\n",
    "\n",
    "    train = df[df['userID'].isin(user_ids)]\n",
    "    test = df[df['userID'].isin(user_ids) == False]\n",
    "\n",
    "    #test데이터셋은 각 유저의 마지막 interaction만 추출\n",
    "    test = test[test['userID'] != test['userID'].shift(-1)]\n",
    "    return train, test\n",
    "\n",
    "def custom_train_test_split_fold_5(df, ratio=0.2, split=True):\n",
    "    \n",
    "    users = list(zip(df['userID'].value_counts().index, df['userID'].value_counts()))\n",
    "    random.shuffle(users)\n",
    "    \n",
    "    max_train_data_len = ratio*len(df)\n",
    "    sum_of_train_data, k = 0, 0\n",
    "    user_ids =[[],[],[],[],[]]\n",
    "\n",
    "    for user_id, count in users:\n",
    "        sum_of_train_data += count\n",
    "        if max_train_data_len < sum_of_train_data:\n",
    "            k += 1\n",
    "            max_train_data_len += ratio*len(df)\n",
    "        user_ids[k].append(user_id)\n",
    "\n",
    "    return user_ids\n",
    "\n",
    "FEATS = [\n",
    "   'KnowledgeTag', 'month', 'hour', 'week', 'elapsed', 'elapsed_cate',\n",
    "   'assessmentItemID0', 'assessmentItemID1', 'assessmentItemID2',\n",
    "   'testId0', 'testId1', 'test0_mean', 'test0_std', 'test1_mean',\n",
    "   'test1_std', 'tag_mean', 'tag_std', 'ass0_mean', 'ass0_std',\n",
    "   'ass1_mean', 'ass1_std', 'ass2_mean', 'ass2_std',\n",
    "'as0_as1', 'as0_as2', 'as1_as2', 'assessmentItemID', 'week_hour']\n",
    "\n",
    "cate = ['KnowledgeTag', 'month', 'hour', 'week', 'elapsed_cate', 'testId0', 'testId1',\n",
    "       'assessmentItemID0', 'assessmentItemID1', 'assessmentItemID2',\n",
    "        'as0_as1', 'as0_as2', 'as1_as2', 'assessmentItemID', 'week_hour']\n",
    "\n",
    "for i in cate:\n",
    "    df[i] = df[i].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1f9af3a-40b4-4f66-b9c1-84d3dfc23823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = custom_train_test_split(df)\n",
    "\n",
    "# y_train = train['answerCode']\n",
    "# train = train.drop(['answerCode'], axis=1)\n",
    "\n",
    "# y_test = test['answerCode']\n",
    "# test = test.drop(['answerCode'], axis=1)\n",
    "train, test, train_y, y_test = train_test_split(df[FEATS], df['answerCode'], test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "989adf21-c231-447c-b0a6-1265944a19ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(train[FEATS], train_y, categorical_feature=cate)\n",
    "lgb_test = lgb.Dataset(test[FEATS], y_test, categorical_feature=cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e9b1808-df3c-436a-af18-d5db09a1b52f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1323032, number of negative: 697732\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15397\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020764, number of used features: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654719 -> initscore=0.639846\n",
      "[LightGBM] [Info] Start training from score 0.639846\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[100]\tvalid_0's auc: 0.824755\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      2\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m          }\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobjective\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbinary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmetric\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlgb_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlgb_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test[FEATS])\n\u001b[1;32m     16\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, np\u001b[38;5;241m.\u001b[39mwhere(preds \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    285\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m    286\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    287\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[1;32m    288\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[1;32m    289\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[1;32m    290\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m--> 292\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m evaluation_result_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 3021\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3022\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {'objective': 'binary', \n",
    "          'metric': 'auc',\n",
    "         }\n",
    "\n",
    "model = lgb.train(\n",
    "    {'objective': 'binary', \n",
    "      'metric': 'auc'},\n",
    "    lgb_train,\n",
    "    valid_sets=[lgb_test],\n",
    "    verbose_eval=100,\n",
    "    num_boost_round=10000,\n",
    "    early_stopping_rounds=1000,\n",
    ")\n",
    "\n",
    "preds = model.predict(test[FEATS])\n",
    "acc = accuracy_score(y_test, np.where(preds >= 0.5, 1, 0))\n",
    "auc = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(f'VALID AUC : {auc} ACC : {acc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1f753c2-ee46-42be-b2f4-98eba208f240",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1324846, number of negative: 696210\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2021056, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655522 -> initscore=0.643400\n",
      "[LightGBM] [Info] Start training from score 0.643400\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's binary_logloss: 0.488578\tvalid_1's binary_logloss: 0.549361\n",
      "[4000]\ttraining's binary_logloss: 0.468831\tvalid_1's binary_logloss: 0.543875\n",
      "Early stopping, best iteration is:\n",
      "[3947]\ttraining's binary_logloss: 0.469215\tvalid_1's binary_logloss: 0.543602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [14:25<57:42, 865.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID AUC : 0.797653390980994 ACC : 0.7242547425474255\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1319364, number of negative: 701387\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020751, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.652908 -> initscore=0.631845\n",
      "[LightGBM] [Info] Start training from score 0.631845\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's binary_logloss: 0.489185\tvalid_1's binary_logloss: 0.550331\n",
      "[4000]\ttraining's binary_logloss: 0.469418\tvalid_1's binary_logloss: 0.545911\n",
      "[6000]\ttraining's binary_logloss: 0.453919\tvalid_1's binary_logloss: 0.543697\n",
      "[8000]\ttraining's binary_logloss: 0.440783\tvalid_1's binary_logloss: 0.542292\n",
      "Early stopping, best iteration is:\n",
      "[7820]\ttraining's binary_logloss: 0.44179\tvalid_1's binary_logloss: 0.541756\n",
      "VALID AUC : 0.796525299235046 ACC : 0.7281045751633987\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [21:24<36:35, 731.74s/it]/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1322890, number of negative: 697645\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020535, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654723 -> initscore=0.639864\n",
      "[LightGBM] [Info] Start training from score 0.639864\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's binary_logloss: 0.490291\tvalid_1's binary_logloss: 0.555067\n",
      "[4000]\ttraining's binary_logloss: 0.469974\tvalid_1's binary_logloss: 0.548404\n",
      "[6000]\ttraining's binary_logloss: 0.454788\tvalid_1's binary_logloss: 0.548941\n",
      "Early stopping, best iteration is:\n",
      "[4819]\ttraining's binary_logloss: 0.463455\tvalid_1's binary_logloss: 0.547923\n",
      "VALID AUC : 0.7933855499386299 ACC : 0.7235023041474654\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [26:28<20:06, 603.41s/it]/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1321992, number of negative: 698756\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020748, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654209 -> initscore=0.637593\n",
      "[LightGBM] [Info] Start training from score 0.637593\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's binary_logloss: 0.489929\tvalid_1's binary_logloss: 0.546025\n",
      "[4000]\ttraining's binary_logloss: 0.470171\tvalid_1's binary_logloss: 0.542128\n",
      "[6000]\ttraining's binary_logloss: 0.454594\tvalid_1's binary_logloss: 0.540959\n",
      "Early stopping, best iteration is:\n",
      "[5641]\ttraining's binary_logloss: 0.457188\tvalid_1's binary_logloss: 0.539906\n",
      "VALID AUC : 0.8020772303595207 ACC : 0.7303523035230353\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [31:56<08:40, 520.79s/it]/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1325260, number of negative: 695474\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020734, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655831 -> initscore=0.644770\n",
      "[LightGBM] [Info] Start training from score 0.644770\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's binary_logloss: 0.490256\tvalid_1's binary_logloss: 0.561497\n",
      "[4000]\ttraining's binary_logloss: 0.470034\tvalid_1's binary_logloss: 0.553987\n",
      "[6000]\ttraining's binary_logloss: 0.454366\tvalid_1's binary_logloss: 0.548985\n",
      "[8000]\ttraining's binary_logloss: 0.441254\tvalid_1's binary_logloss: 0.548278\n",
      "[10000]\ttraining's binary_logloss: 0.429327\tvalid_1's binary_logloss: 0.548843\n",
      "Early stopping, best iteration is:\n",
      "[9075]\ttraining's binary_logloss: 0.434608\tvalid_1's binary_logloss: 0.547623\n",
      "VALID AUC : 0.794195626873839 ACC : 0.7244968771686329\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [39:48<00:00, 477.68s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "user_id = custom_train_test_split_fold_5(df)\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    u = []\n",
    "    for j in range(5):\n",
    "        if j != i:\n",
    "            u += user_id[j]\n",
    "        \n",
    "    train = df[df['userID'].isin(u)]\n",
    "    test = df[df['userID'].isin(u) == False]\n",
    "\n",
    "    #test데이터셋은 각 유저의 마지막 interaction만 추출\n",
    "    test = test[test['userID'] != test['userID'].shift(-1)]\n",
    "    \n",
    "    y_train = train['answerCode']\n",
    "    train = train.drop(['answerCode'], axis=1)\n",
    "\n",
    "    y_test = test['answerCode']\n",
    "    test = test.drop(['answerCode'], axis=1)\n",
    "    \n",
    "    lgb_train = lgb.Dataset(train[FEATS], train_y, categorical_feature=cate)\n",
    "    lgb_test = lgb.Dataset(test[FEATS], y_test, categorical_feature=cate)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        {'objective': 'binary',\n",
    "        'metric': 'auc'}, \n",
    "        lgb_train,\n",
    "        valid_sets=[lgb_train, lgb_test],\n",
    "        verbose_eval=2000,\n",
    "        num_boost_round=20000,\n",
    "        early_stopping_rounds=2000,\n",
    "    )\n",
    "\n",
    "    preds = model.predict(test[FEATS])\n",
    "    acc = accuracy_score(y_test, np.where(preds >= 0.5, 1, 0))\n",
    "    auc = roc_auc_score(y_test, preds)\n",
    "\n",
    "    print(f'VALID AUC : {auc} ACC : {acc}\\n')\n",
    "    \n",
    "    joblib.dump(model, f'lgb_{i}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6df055a3-1d41-4968-ade1-0e993b6a0c10",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1322870, number of negative: 697894\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15147\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020764, number of used features: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654639 -> initscore=0.639492\n",
      "[LightGBM] [Info] Start training from score 0.639492\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\ttraining's auc: 0.828113\tvalid_1's auc: 0.81014\n",
      "[500]\ttraining's auc: 0.838476\tvalid_1's auc: 0.810736\n",
      "[750]\ttraining's auc: 0.844235\tvalid_1's auc: 0.810745\n",
      "[1000]\ttraining's auc: 0.849221\tvalid_1's auc: 0.810701\n",
      "[1250]\ttraining's auc: 0.853314\tvalid_1's auc: 0.810606\n",
      "Early stopping, best iteration is:\n",
      "[830]\ttraining's auc: 0.84589\tvalid_1's auc: 0.810799\n",
      "VALID AUC : 0.8107994139117203 ACC : 0.7676269616304296\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [13:18, 798.24s/it]/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1322870, number of negative: 697895\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15148\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020765, number of used features: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654638 -> initscore=0.639490\n",
      "[LightGBM] [Info] Start training from score 0.639490\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\ttraining's auc: 0.828539\tvalid_1's auc: 0.809316\n",
      "[500]\ttraining's auc: 0.838761\tvalid_1's auc: 0.809971\n",
      "[750]\ttraining's auc: 0.844748\tvalid_1's auc: 0.809942\n",
      "[1000]\ttraining's auc: 0.848757\tvalid_1's auc: 0.809784\n",
      "Early stopping, best iteration is:\n",
      "[549]\ttraining's auc: 0.839939\tvalid_1's auc: 0.809998\n",
      "VALID AUC : 0.8099979384309715 ACC : 0.7674721046099396\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [19:32, 670.94s/it]/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1322870, number of negative: 697895\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15143\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020765, number of used features: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654638 -> initscore=0.639490\n",
      "[LightGBM] [Info] Start training from score 0.639490\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\ttraining's auc: 0.828146\tvalid_1's auc: 0.810623\n",
      "[500]\ttraining's auc: 0.838739\tvalid_1's auc: 0.811084\n",
      "[750]\ttraining's auc: 0.844697\tvalid_1's auc: 0.811289\n",
      "[1000]\ttraining's auc: 0.849254\tvalid_1's auc: 0.811157\n",
      "Early stopping, best iteration is:\n",
      "[701]\ttraining's auc: 0.843956\tvalid_1's auc: 0.811304\n",
      "VALID AUC : 0.8113044171325368 ACC : 0.768172829682239\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [23:30, 541.23s/it]/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1322871, number of negative: 697894\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15149\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020765, number of used features: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654639 -> initscore=0.639492\n",
      "[LightGBM] [Info] Start training from score 0.639492\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\ttraining's auc: 0.828281\tvalid_1's auc: 0.810791\n",
      "[500]\ttraining's auc: 0.838265\tvalid_1's auc: 0.811462\n",
      "[750]\ttraining's auc: 0.844563\tvalid_1's auc: 0.811664\n",
      "[1000]\ttraining's auc: 0.849004\tvalid_1's auc: 0.811582\n",
      "Early stopping, best iteration is:\n",
      "[729]\ttraining's auc: 0.844095\tvalid_1's auc: 0.811691\n",
      "VALID AUC : 0.8116908494982766 ACC : 0.768689465964358\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [39:42, 670.38s/it]/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1322871, number of negative: 697894\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15158\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020765, number of used features: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654639 -> initscore=0.639492\n",
      "[LightGBM] [Info] Start training from score 0.639492\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\ttraining's auc: 0.827844\tvalid_1's auc: 0.810845\n",
      "[500]\ttraining's auc: 0.838544\tvalid_1's auc: 0.811741\n",
      "[750]\ttraining's auc: 0.845421\tvalid_1's auc: 0.811813\n",
      "[1000]\ttraining's auc: 0.850003\tvalid_1's auc: 0.811652\n",
      "Early stopping, best iteration is:\n",
      "[680]\ttraining's auc: 0.843612\tvalid_1's auc: 0.811861\n",
      "VALID AUC : 0.8118611706677159 ACC : 0.7686261235849411\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [1:02:13, 746.78s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "X, y = df[FEATS], df['answerCode']\n",
    "\n",
    "for i, (train_index, test_index) in tqdm(enumerate(str_kf.split(X, y))):\n",
    "    train, test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(train[FEATS], y_train, categorical_feature=cate)\n",
    "    lgb_test = lgb.Dataset(test[FEATS], y_test, categorical_feature=cate)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        {'objective': 'binary',\n",
    "        'metric': 'auc'}, \n",
    "        lgb_train,\n",
    "        valid_sets=[lgb_train, lgb_test],\n",
    "        verbose_eval=250,\n",
    "        num_boost_round=10000,\n",
    "#        early_stopping_rounds=500,\n",
    "    )\n",
    "\n",
    "    preds = model.predict(test[FEATS])\n",
    "    acc = accuracy_score(y_test, np.where(preds >= 0.5, 1, 0))\n",
    "    auc = roc_auc_score(y_test, preds)\n",
    "\n",
    "    print(f'VALID AUC : {auc} ACC : {acc}\\n')\n",
    "    \n",
    "    joblib.dump(model, f'lgb_{i}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "138ee944-88b6-4091-baff-14f9f4e4f6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.76it/s]\n"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv('../../data/infer.csv')\n",
    "#sub = test[test['answerCode'] == -1]\n",
    "\n",
    "p = []\n",
    "for i in cate:\n",
    "    sub[i] = sub[i].astype('category')\n",
    "    \n",
    "for i in tqdm(range(5)):\n",
    "    load_model = joblib.load(f'lgb_{i}.pkl')\n",
    "    preds = load_model.predict(sub[FEATS])\n",
    "    p.append(preds)\n",
    "\n",
    "s = pd.read_csv('output/submission.csv')\n",
    "m = (p[0] + p[1] + p[2] + p[3] + p[4])/5\n",
    "s['prediction'] = m\n",
    "\n",
    "s.to_csv('output/submission_lgbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "798ffc55-154a-44b3-ac55-74c584e04e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_mean</th>\n",
       "      <th>tag_std</th>\n",
       "      <th>ass0_mean</th>\n",
       "      <th>ass0_std</th>\n",
       "      <th>ass1_mean</th>\n",
       "      <th>ass1_std</th>\n",
       "      <th>ass2_mean</th>\n",
       "      <th>ass2_std</th>\n",
       "      <th>elo_prob</th>\n",
       "      <th>as0_as1</th>\n",
       "      <th>as0_as2</th>\n",
       "      <th>as1_as2</th>\n",
       "      <th>assessmentItemID</th>\n",
       "      <th>week_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.559692</td>\n",
       "      <td>0.496500</td>\n",
       "      <td>0.659086</td>\n",
       "      <td>0.474017</td>\n",
       "      <td>0.654069</td>\n",
       "      <td>0.475687</td>\n",
       "      <td>0.455291</td>\n",
       "      <td>0.498000</td>\n",
       "      <td>0.473301</td>\n",
       "      <td>422</td>\n",
       "      <td>67</td>\n",
       "      <td>1273</td>\n",
       "      <td>A050133008</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.547059</td>\n",
       "      <td>0.497878</td>\n",
       "      <td>0.521662</td>\n",
       "      <td>0.499531</td>\n",
       "      <td>0.752487</td>\n",
       "      <td>0.431590</td>\n",
       "      <td>0.455291</td>\n",
       "      <td>0.498000</td>\n",
       "      <td>0.569538</td>\n",
       "      <td>515</td>\n",
       "      <td>76</td>\n",
       "      <td>1471</td>\n",
       "      <td>A070146008</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.494333</td>\n",
       "      <td>0.500051</td>\n",
       "      <td>0.521662</td>\n",
       "      <td>0.499531</td>\n",
       "      <td>0.648133</td>\n",
       "      <td>0.477569</td>\n",
       "      <td>0.455291</td>\n",
       "      <td>0.498000</td>\n",
       "      <td>0.191112</td>\n",
       "      <td>984</td>\n",
       "      <td>76</td>\n",
       "      <td>1330</td>\n",
       "      <td>A070111008</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.493849</td>\n",
       "      <td>0.454675</td>\n",
       "      <td>0.497943</td>\n",
       "      <td>0.648571</td>\n",
       "      <td>0.477437</td>\n",
       "      <td>0.556916</td>\n",
       "      <td>0.496751</td>\n",
       "      <td>0.394117</td>\n",
       "      <td>1202</td>\n",
       "      <td>37</td>\n",
       "      <td>1234</td>\n",
       "      <td>A090064006</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.609474</td>\n",
       "      <td>0.487920</td>\n",
       "      <td>0.712236</td>\n",
       "      <td>0.452722</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.478178</td>\n",
       "      <td>0.515859</td>\n",
       "      <td>0.499750</td>\n",
       "      <td>0.345771</td>\n",
       "      <td>911</td>\n",
       "      <td>5</td>\n",
       "      <td>1188</td>\n",
       "      <td>A060135007</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>0.701429</td>\n",
       "      <td>0.457740</td>\n",
       "      <td>0.680253</td>\n",
       "      <td>0.466379</td>\n",
       "      <td>0.673308</td>\n",
       "      <td>0.469021</td>\n",
       "      <td>0.599453</td>\n",
       "      <td>0.490010</td>\n",
       "      <td>0.101355</td>\n",
       "      <td>951</td>\n",
       "      <td>31</td>\n",
       "      <td>1251</td>\n",
       "      <td>A040122005</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>0.824583</td>\n",
       "      <td>0.380363</td>\n",
       "      <td>0.702195</td>\n",
       "      <td>0.457294</td>\n",
       "      <td>0.648133</td>\n",
       "      <td>0.477569</td>\n",
       "      <td>0.599453</td>\n",
       "      <td>0.490010</td>\n",
       "      <td>0.761471</td>\n",
       "      <td>1107</td>\n",
       "      <td>52</td>\n",
       "      <td>971</td>\n",
       "      <td>A030111005</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>0.823881</td>\n",
       "      <td>0.380979</td>\n",
       "      <td>0.659086</td>\n",
       "      <td>0.474017</td>\n",
       "      <td>0.772090</td>\n",
       "      <td>0.419516</td>\n",
       "      <td>0.663597</td>\n",
       "      <td>0.472479</td>\n",
       "      <td>0.782659</td>\n",
       "      <td>1462</td>\n",
       "      <td>55</td>\n",
       "      <td>1384</td>\n",
       "      <td>A050193004</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>0.823881</td>\n",
       "      <td>0.380979</td>\n",
       "      <td>0.659086</td>\n",
       "      <td>0.474017</td>\n",
       "      <td>0.772090</td>\n",
       "      <td>0.419516</td>\n",
       "      <td>0.663597</td>\n",
       "      <td>0.472479</td>\n",
       "      <td>0.597028</td>\n",
       "      <td>1462</td>\n",
       "      <td>55</td>\n",
       "      <td>1384</td>\n",
       "      <td>A050193004</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>0.638519</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>0.680253</td>\n",
       "      <td>0.466379</td>\n",
       "      <td>0.608084</td>\n",
       "      <td>0.488195</td>\n",
       "      <td>0.599453</td>\n",
       "      <td>0.490010</td>\n",
       "      <td>0.571506</td>\n",
       "      <td>954</td>\n",
       "      <td>31</td>\n",
       "      <td>1200</td>\n",
       "      <td>A040130005</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>744 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tag_mean   tag_std  ass0_mean  ass0_std  ass1_mean  ass1_std  ass2_mean  \\\n",
       "0    0.559692  0.496500   0.659086  0.474017   0.654069  0.475687   0.455291   \n",
       "1    0.547059  0.497878   0.521662  0.499531   0.752487  0.431590   0.455291   \n",
       "2    0.494333  0.500051   0.521662  0.499531   0.648133  0.477569   0.455291   \n",
       "3    0.420000  0.493849   0.454675  0.497943   0.648571  0.477437   0.556916   \n",
       "4    0.609474  0.487920   0.712236  0.452722   0.646154  0.478178   0.515859   \n",
       "..        ...       ...        ...       ...        ...       ...        ...   \n",
       "739  0.701429  0.457740   0.680253  0.466379   0.673308  0.469021   0.599453   \n",
       "740  0.824583  0.380363   0.702195  0.457294   0.648133  0.477569   0.599453   \n",
       "741  0.823881  0.380979   0.659086  0.474017   0.772090  0.419516   0.663597   \n",
       "742  0.823881  0.380979   0.659086  0.474017   0.772090  0.419516   0.663597   \n",
       "743  0.638519  0.480519   0.680253  0.466379   0.608084  0.488195   0.599453   \n",
       "\n",
       "     ass2_std  elo_prob  as0_as1  as0_as2  as1_as2 assessmentItemID  week_hour  \n",
       "0    0.498000  0.473301      422       67     1273       A050133008         64  \n",
       "1    0.498000  0.569538      515       76     1471       A070146008         22  \n",
       "2    0.498000  0.191112      984       76     1330       A070111008         61  \n",
       "3    0.496751  0.394117     1202       37     1234       A090064006        111  \n",
       "4    0.499750  0.345771      911        5     1188       A060135007         55  \n",
       "..        ...       ...      ...      ...      ...              ...        ...  \n",
       "739  0.490010  0.101355      951       31     1251       A040122005         17  \n",
       "740  0.490010  0.761471     1107       52      971       A030111005         73  \n",
       "741  0.472479  0.782659     1462       55     1384       A050193004         22  \n",
       "742  0.472479  0.597028     1462       55     1384       A050193004         90  \n",
       "743  0.490010  0.571506      954       31     1200       A040130005         16  \n",
       "\n",
       "[744 rows x 14 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train = pd.read_csv('../../data/elo.csv')\n",
    "#train.columns\n",
    "q = pd.DataFrame([])\n",
    "q['as0_as1'] =  np.array([str(i)+'_'+str(j) for i, j in zip(list(df.assessmentItemID0), list(df.assessmentItemID1))])\n",
    "q['as0_as2'] =  np.array([str(i)+'_'+str(j) for i, j in zip(list(df.assessmentItemID0), list(df.assessmentItemID2))])\n",
    "q['as1_as2'] =  np.array([str(i)+'_'+str(j) for i, j in zip(list(df.assessmentItemID1), list(df.assessmentItemID2))])\n",
    "q['week_hour'] =  np.array([str(i)+'_'+str(j) for i, j in zip(list(df.week), list(df.hour))])\n",
    "\n",
    "\n",
    "sub['week_hour'] =  [str(i)+'_'+str(j) for i, j in zip(list(sub.week), list(sub.hour))]\n",
    "sub['as0_as1'] =  [str(i)+'_'+str(j) for i, j in zip(list(sub.assessmentItemID0), list(sub.assessmentItemID1))]\n",
    "sub['as0_as2'] =  [str(i)+'_'+str(j) for i, j in zip(list(sub.assessmentItemID0), list(sub.assessmentItemID2))]\n",
    "sub['as1_as2'] =  [str(i)+'_'+str(j) for i, j in zip(list(sub.assessmentItemID1), list(sub.assessmentItemID2))]\n",
    "\n",
    "\n",
    "cate = ['as0_as1', 'as0_as2', 'as1_as2', 'week_hour']\n",
    "label = [as0_as1, as0_as2, as1_as2, week_hour]\n",
    "for index, col in enumerate(cate):\n",
    "    cate2label = {j:i for i,j in enumerate(q[col].unique())}\n",
    "    sub[col] = sub[col].map(cate2label)\n",
    "    \n",
    "sub[FEATS[15:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28d65d5a-4c50-4be0-a6e5-fc8ebc189d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('output/output (3).csv')\n",
    "b = pd.read_csv('output/submission_lgbm.csv')\n",
    "\n",
    "c = (a['prediction'] + b['prediction'])/2\n",
    "b['prediction'] = c\n",
    "b.to_csv('output/h.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d439c0-f99a-44f2-aae0-002619057838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
