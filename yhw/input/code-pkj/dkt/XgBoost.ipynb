{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac8ed6f0-ea4d-470a-a16c-4d2a7b635062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3910bfa7-8f88-43d2-9eb5-57d2233e22fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATS = [\n",
    "   'KnowledgeTag', 'month', 'hour', 'week', 'elapsed', 'elapsed_cate',\n",
    "   'assessmentItemID0', 'assessmentItemID1', 'assessmentItemID2',\n",
    "   'testId0', 'testId1', 'test0_mean', 'test0_std', 'test1_mean',\n",
    "   'test1_std', 'tag_mean', 'tag_std', 'ass0_mean', 'ass0_std',\n",
    "   'ass1_mean', 'ass1_std', 'ass2_mean', 'ass2_std',\n",
    "'as0_as1', 'as0_as2', 'as1_as2', 'assessmentItemID', 'week_hour']\n",
    "\n",
    "cate = ['KnowledgeTag', 'month', 'hour', 'week', 'elapsed_cate', 'testId0', 'testId1',\n",
    "       'assessmentItemID0', 'assessmentItemID1', 'assessmentItemID2',\n",
    "        'as0_as1', 'as0_as2', 'as1_as2', 'assessmentItemID', 'week_hour']\n",
    "\n",
    "df = pd.read_csv('../../data/elo.csv')\n",
    "\n",
    "for i in cate:\n",
    "    df[i] = df[i].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4659589f-6475-4c08-97e3-6e5afccbc772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[FEATS], df['answerCode'], test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
    "dtest  = xgb.DMatrix(X_test,  y_test, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b3739b8-9d75-4d10-a8ce-579198654df6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID AUC : 0.6981963973604752 ACC : 0.7625991702164722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "watchlist = [(dtrain, 'train'), (dtest, 'test')]\n",
    "params = {\n",
    "    'booster': 'gbtree', \n",
    "    'objective': 'binary:logistic',\n",
    "    # 'subsample': 0.8,          # 80% of data to grow trees and prevent overfitting\n",
    "    # 'colsample_bytree': 0.85,  # 85% of features used\n",
    "    # 'eta': 0.1, \n",
    "    # 'max_depth': 6, \n",
    "    'seed': 42,\n",
    "    'eval_metric': 'auc'}\n",
    "# xgb_cv = xgb.cv(dtrain=dtrain, params=params, nfold=3,\n",
    "#                     num_boost_round=500, early_stopping_rounds=10, metrics=\"auc\", as_pandas=True, seed=123)\n",
    "\n",
    "# xgb_cv.head()\n",
    "\n",
    "xgb_model = xgb.train(params, dtrain, 100, evals = watchlist,\n",
    "                      early_stopping_rounds = 50, verbose_eval = 100)\n",
    "\n",
    "preds = xgb_model.predict(dtest)\n",
    "acc = accuracy_score(y_test, np.where(preds >= 0.5, 1, 0))\n",
    "auc = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(f'VALID AUC : {auc} ACC : {acc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68d35672-f40d-4a7e-822b-e63a8865577a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.73949\ttest-auc:0.73841\n",
      "[100]\ttrain-auc:0.78316\ttest-auc:0.77811\n",
      "[200]\ttrain-auc:0.79717\ttest-auc:0.78948\n",
      "[249]\ttrain-auc:0.80153\ttest-auc:0.79248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [04:03, 243.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID AUC : 0.792481712024945 ACC : 0.7587550871747771\n",
      "\n",
      "[0]\ttrain-auc:0.73923\ttest-auc:0.73822\n",
      "[100]\ttrain-auc:0.78359\ttest-auc:0.77785\n",
      "[200]\ttrain-auc:0.79683\ttest-auc:0.78796\n",
      "[249]\ttrain-auc:0.80153\ttest-auc:0.79137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [07:53, 239.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID AUC : 0.7913732770288868 ACC : 0.7582854801451332\n",
      "\n",
      "[0]\ttrain-auc:0.73895\ttest-auc:0.73945\n",
      "[100]\ttrain-auc:0.78282\ttest-auc:0.77936\n",
      "[200]\ttrain-auc:0.79637\ttest-auc:0.78977\n",
      "[249]\ttrain-auc:0.80141\ttest-auc:0.79350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [11:44, 236.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID AUC : 0.7935000067899785 ACC : 0.7594315813227076\n",
      "\n",
      "[0]\ttrain-auc:0.73890\ttest-auc:0.73940\n",
      "[100]\ttrain-auc:0.78234\ttest-auc:0.77829\n",
      "[200]\ttrain-auc:0.79678\ttest-auc:0.78972\n",
      "[249]\ttrain-auc:0.80139\ttest-auc:0.79313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [15:32, 234.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID AUC : 0.7931303472921546 ACC : 0.7591702940076129\n",
      "\n",
      "[0]\ttrain-auc:0.73924\ttest-auc:0.73905\n",
      "[100]\ttrain-auc:0.78320\ttest-auc:0.77918\n",
      "[200]\ttrain-auc:0.79667\ttest-auc:0.78982\n",
      "[249]\ttrain-auc:0.80097\ttest-auc:0.79291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [19:26, 233.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID AUC : 0.7929105050250722 ACC : 0.7588892121989504\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "params = {\n",
    "    'booster': 'gbtree', \n",
    "    'objective': 'binary:logistic',\n",
    "    'seed': 42,\n",
    "    'eval_metric': 'auc'}\n",
    "\n",
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "X, y = df[FEATS], df['answerCode']\n",
    "p =[]\n",
    "for i, (train_index, test_index) in tqdm(enumerate(str_kf.split(X, y))):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
    "    dtest  = xgb.DMatrix(X_test,  y_test, enable_categorical=True)\n",
    "    \n",
    "    watchlist = [(dtrain, 'train'), (dtest, 'test')]\n",
    "    \n",
    "    xgb_model = xgb.train(params, dtrain, 250, evals = watchlist,\n",
    "                          early_stopping_rounds = 500, verbose_eval = 100)\n",
    "\n",
    "    \n",
    "    preds = xgb_model.predict(dtest)\n",
    "    acc = accuracy_score(y_test, np.where(preds >= 0.5, 1, 0))\n",
    "    auc = roc_auc_score(y_test, preds)\n",
    "    p.append(xgb_model.predict(dsub))\n",
    "    print(f'VALID AUC : {auc} ACC : {acc}\\n')\n",
    "    \n",
    "    xgb_model.save_model(f'xgboost/model/catboost_{i}.model')\n",
    "    \n",
    "m = (p[0] + p[1] + p[2] + p[3] + p[4])/5\n",
    "s['prediction'] = m\n",
    "\n",
    "s.to_csv('output/submission_xgb_elo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "759e4cd8-7e12-40bf-9e68-392dec93803b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 17.32it/s]\n"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv('../../data/infer.csv')\n",
    "\n",
    "for i in cate:\n",
    "    sub[i] = sub[i].astype('category')\n",
    "p = []\n",
    "dsub  = xgb.DMatrix(sub[FEATS], sub['answerCode'], enable_categorical=True)\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    new_xgb_model = xgb.Booster(params)\n",
    "    new_xgb_model.load_model(f'xgboost/model/catboost_{i}.model') \n",
    "    preds = new_xgb_model.predict(dsub)\n",
    "    p.append(preds)\n",
    "    \n",
    "s = pd.read_csv('output/submission.csv')\n",
    "m = (p[0] + p[1] + p[2] + p[3] + p[4])/5\n",
    "s['prediction'] = m\n",
    "\n",
    "s.to_csv('output/submission_xgb_elo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac9a94c4-8d50-41ec-9bff-c8c4bd027051",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [505192, 744]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [51], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m new_xgb_model\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgboost/model/catboost_1.model\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      4\u001b[0m preds \u001b[38;5;241m=\u001b[39m new_xgb_model\u001b[38;5;241m.\u001b[39mpredict(dtest)\n\u001b[0;32m----> 5\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, preds)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVALID AUC : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ACC : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    385\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    390\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [505192, 744]"
     ]
    }
   ],
   "source": [
    "new_xgb_model = xgb.Booster()\n",
    "new_xgb_model.load_model(f'xgboost/model/catboost_1.model') \n",
    "    \n",
    "preds = new_xgb_model.predict(dtest)\n",
    "acc = accuracy_score(y_test, np.where(preds >= 0.5, 1, 0))\n",
    "auc = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(f'VALID AUC : {auc} ACC : {acc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277eeb4c-a8da-4fd9-970e-33db9d858880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
