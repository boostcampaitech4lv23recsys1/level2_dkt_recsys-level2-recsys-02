{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8657179-b18c-4473-9006-a0e9c4d7f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import joblib\n",
    "\n",
    "lgb_train = lgb.Dataset(X[FEATS], y)\n",
    "lgb_test = lgb.Dataset(test[FEATS], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e8c6abb-e375-4b2f-9df2-97be4a9d26ff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1320806, number of negative: 699865\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3382\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020671, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.653647 -> initscore=0.635110\n",
      "[LightGBM] [Info] Start training from score 0.635110\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.604177\n",
      "[200]\tvalid_0's binary_logloss: 0.59452\n",
      "[300]\tvalid_0's binary_logloss: 0.588991\n",
      "[400]\tvalid_0's binary_logloss: 0.584086\n",
      "[500]\tvalid_0's binary_logloss: 0.581453\n",
      "[600]\tvalid_0's binary_logloss: 0.576971\n",
      "[700]\tvalid_0's binary_logloss: 0.574343\n",
      "[800]\tvalid_0's binary_logloss: 0.571841\n",
      "[900]\tvalid_0's binary_logloss: 0.571095\n",
      "[1000]\tvalid_0's binary_logloss: 0.569545\n",
      "[1100]\tvalid_0's binary_logloss: 0.56797\n",
      "[1200]\tvalid_0's binary_logloss: 0.56626\n",
      "[1300]\tvalid_0's binary_logloss: 0.565789\n",
      "[1400]\tvalid_0's binary_logloss: 0.564905\n",
      "[1500]\tvalid_0's binary_logloss: 0.564662\n",
      "[1600]\tvalid_0's binary_logloss: 0.563687\n",
      "[1700]\tvalid_0's binary_logloss: 0.56427\n",
      "[1800]\tvalid_0's binary_logloss: 0.564033\n",
      "[1900]\tvalid_0's binary_logloss: 0.562963\n",
      "[2000]\tvalid_0's binary_logloss: 0.562659\n",
      "[2100]\tvalid_0's binary_logloss: 0.562143\n",
      "[2200]\tvalid_0's binary_logloss: 0.561406\n",
      "[2300]\tvalid_0's binary_logloss: 0.560627\n",
      "[2400]\tvalid_0's binary_logloss: 0.560778\n",
      "[2500]\tvalid_0's binary_logloss: 0.560781\n",
      "[2600]\tvalid_0's binary_logloss: 0.560185\n",
      "[2700]\tvalid_0's binary_logloss: 0.560155\n",
      "[2800]\tvalid_0's binary_logloss: 0.560603\n",
      "[2900]\tvalid_0's binary_logloss: 0.560073\n",
      "[3000]\tvalid_0's binary_logloss: 0.560278\n",
      "[3100]\tvalid_0's binary_logloss: 0.560415\n",
      "[3200]\tvalid_0's binary_logloss: 0.559982\n",
      "[3300]\tvalid_0's binary_logloss: 0.559981\n",
      "[3400]\tvalid_0's binary_logloss: 0.559867\n",
      "[3500]\tvalid_0's binary_logloss: 0.559865\n",
      "[3600]\tvalid_0's binary_logloss: 0.559453\n",
      "[3700]\tvalid_0's binary_logloss: 0.559407\n",
      "[3800]\tvalid_0's binary_logloss: 0.559138\n",
      "[3900]\tvalid_0's binary_logloss: 0.5588\n",
      "[4000]\tvalid_0's binary_logloss: 0.558798\n",
      "[4100]\tvalid_0's binary_logloss: 0.558877\n",
      "[4200]\tvalid_0's binary_logloss: 0.558871\n",
      "[4300]\tvalid_0's binary_logloss: 0.55871\n",
      "[4400]\tvalid_0's binary_logloss: 0.558098\n",
      "[4500]\tvalid_0's binary_logloss: 0.557823\n",
      "[4600]\tvalid_0's binary_logloss: 0.558108\n",
      "[4700]\tvalid_0's binary_logloss: 0.557738\n",
      "[4800]\tvalid_0's binary_logloss: 0.557722\n",
      "[4900]\tvalid_0's binary_logloss: 0.557576\n",
      "[5000]\tvalid_0's binary_logloss: 0.557733\n",
      "[5100]\tvalid_0's binary_logloss: 0.558297\n",
      "[5200]\tvalid_0's binary_logloss: 0.558413\n",
      "Early stopping, best iteration is:\n",
      "[4775]\tvalid_0's binary_logloss: 0.557423\n",
      "VALID AUC : 0.785345119555646 ACC : 0.7143786597267404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(\n",
    "    {'objective': 'binary'}, \n",
    "    lgb_train,\n",
    "    valid_sets=[lgb_test],\n",
    "    verbose_eval=100,\n",
    "    num_boost_round=10000,\n",
    "    early_stopping_rounds=500,\n",
    ")\n",
    "\n",
    "preds = model.predict(test[FEATS])\n",
    "acc = accuracy_score(y_test, np.where(preds >= 0.5, 1, 0))\n",
    "auc = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(f'VALID AUC : {auc} ACC : {acc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aba3f02-5a74-4378-9d6d-c22a3fb85457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef58455e-dbc8-43b8-af1d-5f217f11b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../../../data/test.csv')\n",
    "sub = test[test['answerCode'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dc28bd8-38de-43b0-bc5f-22f23adf7a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.33it/s]\n"
     ]
    }
   ],
   "source": [
    "p = []\n",
    "\n",
    "FEATS = [\n",
    "       'KnowledgeTag', 'month', 'hour', 'week', 'elapsed', 'elapsed_cate',\n",
    "       'assessmentItemID0', 'assessmentItemID1', 'assessmentItemID2',\n",
    "        'tag_mean', 'tag_std', 'ass0_mean', 'ass0_std',\n",
    "       'ass1_mean', 'ass1_std', 'ass2_mean', 'ass2_std',\n",
    "       'user_total_answer']\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    load_model = joblib.load(f'lgb_{i}.pkl')\n",
    "    preds = load_model.predict(sub[FEATS])\n",
    "    p.append(preds)\n",
    "\n",
    "#preds = model.predict(sub[FEATS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5550464-12ee-4358-9827-0a1ca0564bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.read_csv('../output/submission.csv')\n",
    "m = (p[0] + p[1] + p[2] + p[3] + p[4])/5\n",
    "s['prediction'] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a878375-de07-4377-b6ca-3abd4f906ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_csv('../output/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a2343c4-672f-4ba0-b7f9-b7a0ffe77c3c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1322870, number of negative: 697894\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020764, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654639 -> initscore=0.639492\n",
      "[LightGBM] [Info] Start training from score 0.639492\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.502915\tvalid_1's binary_logloss: 0.522087\n",
      "[2000]\ttraining's binary_logloss: 0.488195\tvalid_1's binary_logloss: 0.516882\n",
      "[3000]\ttraining's binary_logloss: 0.477446\tvalid_1's binary_logloss: 0.515208\n",
      "[4000]\ttraining's binary_logloss: 0.468539\tvalid_1's binary_logloss: 0.514793\n",
      "[5000]\ttraining's binary_logloss: 0.460291\tvalid_1's binary_logloss: 0.514409\n",
      "Early stopping, best iteration is:\n",
      "[4595]\ttraining's binary_logloss: 0.463525\tvalid_1's binary_logloss: 0.514375\n",
      "VALID AUC : 0.7885261931610134 ACC : 0.7558829118434179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [04:29, 269.48s/it]/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1322870, number of negative: 697895\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020765, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654638 -> initscore=0.639490\n",
      "[LightGBM] [Info] Start training from score 0.639490\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.504509\tvalid_1's binary_logloss: 0.514961\n",
      "[2000]\ttraining's binary_logloss: 0.489331\tvalid_1's binary_logloss: 0.509794\n",
      "[3000]\ttraining's binary_logloss: 0.478414\tvalid_1's binary_logloss: 0.507531\n",
      "[4000]\ttraining's binary_logloss: 0.469049\tvalid_1's binary_logloss: 0.506921\n",
      "Early stopping, best iteration is:\n",
      "[3620]\ttraining's binary_logloss: 0.472232\tvalid_1's binary_logloss: 0.506786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [08:11, 255.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID AUC : 0.7968681854094036 ACC : 0.7605915386457796\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1322870, number of negative: 697895\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020765, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654638 -> initscore=0.639490\n",
      "[LightGBM] [Info] Start training from score 0.639490\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.505107\tvalid_1's binary_logloss: 0.516247\n",
      "[2000]\ttraining's binary_logloss: 0.489655\tvalid_1's binary_logloss: 0.510024\n",
      "[3000]\ttraining's binary_logloss: 0.478681\tvalid_1's binary_logloss: 0.507718\n",
      "[4000]\ttraining's binary_logloss: 0.469644\tvalid_1's binary_logloss: 0.507002\n",
      "[5000]\ttraining's binary_logloss: 0.461333\tvalid_1's binary_logloss: 0.506827\n",
      "Early stopping, best iteration is:\n",
      "[4632]\ttraining's binary_logloss: 0.464296\tvalid_1's binary_logloss: 0.506602\n",
      "VALID AUC : 0.796214514907617 ACC : 0.7606786344174777\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [12:43, 260.20s/it]/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1322871, number of negative: 697894\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020765, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654639 -> initscore=0.639492\n",
      "[LightGBM] [Info] Start training from score 0.639492\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.504961\tvalid_1's binary_logloss: 0.512287\n",
      "[2000]\ttraining's binary_logloss: 0.48983\tvalid_1's binary_logloss: 0.506127\n",
      "[3000]\ttraining's binary_logloss: 0.479019\tvalid_1's binary_logloss: 0.503517\n",
      "[4000]\ttraining's binary_logloss: 0.469705\tvalid_1's binary_logloss: 0.502388\n",
      "[5000]\ttraining's binary_logloss: 0.461417\tvalid_1's binary_logloss: 0.501994\n",
      "Early stopping, best iteration is:\n",
      "[4848]\ttraining's binary_logloss: 0.462621\tvalid_1's binary_logloss: 0.501888\n",
      "VALID AUC : 0.8007568325274818 ACC : 0.7642792527974568\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [17:28, 267.74s/it]/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1322871, number of negative: 697894\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2617\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020765, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654639 -> initscore=0.639492\n",
      "[LightGBM] [Info] Start training from score 0.639492\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.504479\tvalid_1's binary_logloss: 0.517238\n",
      "[2000]\ttraining's binary_logloss: 0.489148\tvalid_1's binary_logloss: 0.511267\n",
      "[3000]\ttraining's binary_logloss: 0.478538\tvalid_1's binary_logloss: 0.509733\n",
      "[4000]\ttraining's binary_logloss: 0.469674\tvalid_1's binary_logloss: 0.509303\n",
      "Early stopping, best iteration is:\n",
      "[3945]\ttraining's binary_logloss: 0.470094\tvalid_1's binary_logloss: 0.509278\n",
      "VALID AUC : 0.793120181476388 ACC : 0.7593484444497229\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [21:24, 256.85s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_splits = 5\n",
    "str_kf = StratifiedKFold(n_splits = n_splits)\n",
    "\n",
    "y = df['answerCode']\n",
    "X = df.drop(['answerCode'], axis=1)\n",
    "\n",
    "for i, (train_index, test_index) in tqdm(enumerate(str_kf.split(X, y))):\n",
    "    X_train, X_valid = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_valid = y.loc[train_index], y.loc[test_index]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_train[FEATS], y_train)\n",
    "    lgb_test = lgb.Dataset(X_valid[FEATS], y_valid)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        {'objective': 'binary'}, \n",
    "        lgb_train,\n",
    "        valid_sets=[lgb_train, lgb_test],\n",
    "        verbose_eval=1000,\n",
    "        num_boost_round=20000,\n",
    "        early_stopping_rounds=500,\n",
    "    )\n",
    "\n",
    "    preds = model.predict(X_valid[FEATS])\n",
    "    acc = accuracy_score(y_valid, np.where(preds >= 0.5, 1, 0))\n",
    "    auc = roc_auc_score(y_valid, preds)\n",
    "\n",
    "    print(f'VALID AUC : {auc} ACC : {acc}\\n')\n",
    "    \n",
    "    joblib.dump(model, f'lgb_{i}.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
